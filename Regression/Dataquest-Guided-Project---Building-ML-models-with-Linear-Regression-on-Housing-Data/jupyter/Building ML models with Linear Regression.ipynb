{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('../datasets/AmesHousing.tsv', delimiter=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def transform_features(data):\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "def select_features(df):\n",
    "    return df[[\"Gr Liv Area\", \"SalePrice\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "57088.25161263909"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def train_and_test(df):\n",
    "    train = df.iloc[:1460]\n",
    "    test = df.iloc[1460:]\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    features = train.select_dtypes(include=['int', 'float']).drop(columns=\"SalePrice\").columns\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "    test_predictions = lr.predict(test[features])\n",
    "\n",
    "    test_mse = mean_squared_error(test_predictions, test['SalePrice'])\n",
    "    \n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return test_rmse\n",
    "\n",
    "filtered_df = select_features(data)\n",
    "rmse = train_and_test(filtered_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Clean the data and select transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 71 columns):\n",
      "Order              2930 non-null int64\n",
      "PID                2930 non-null int64\n",
      "MS SubClass        2930 non-null int64\n",
      "MS Zoning          2930 non-null object\n",
      "Lot Area           2930 non-null int64\n",
      "Street             2930 non-null object\n",
      "Lot Shape          2930 non-null object\n",
      "Land Contour       2930 non-null object\n",
      "Utilities          2930 non-null object\n",
      "Lot Config         2930 non-null object\n",
      "Land Slope         2930 non-null object\n",
      "Neighborhood       2930 non-null object\n",
      "Condition 1        2930 non-null object\n",
      "Condition 2        2930 non-null object\n",
      "Bldg Type          2930 non-null object\n",
      "House Style        2930 non-null object\n",
      "Overall Qual       2930 non-null int64\n",
      "Overall Cond       2930 non-null int64\n",
      "Year Built         2930 non-null int64\n",
      "Year Remod/Add     2930 non-null int64\n",
      "Roof Style         2930 non-null object\n",
      "Roof Matl          2930 non-null object\n",
      "Exterior 1st       2930 non-null object\n",
      "Exterior 2nd       2930 non-null object\n",
      "Mas Vnr Type       2907 non-null object\n",
      "Mas Vnr Area       2907 non-null float64\n",
      "Exter Qual         2930 non-null object\n",
      "Exter Cond         2930 non-null object\n",
      "Foundation         2930 non-null object\n",
      "Bsmt Qual          2850 non-null object\n",
      "Bsmt Cond          2850 non-null object\n",
      "Bsmt Exposure      2847 non-null object\n",
      "BsmtFin Type 1     2850 non-null object\n",
      "BsmtFin SF 1       2929 non-null float64\n",
      "BsmtFin Type 2     2849 non-null object\n",
      "BsmtFin SF 2       2929 non-null float64\n",
      "Bsmt Unf SF        2929 non-null float64\n",
      "Total Bsmt SF      2929 non-null float64\n",
      "Heating            2930 non-null object\n",
      "Heating QC         2930 non-null object\n",
      "Central Air        2930 non-null object\n",
      "Electrical         2929 non-null object\n",
      "1st Flr SF         2930 non-null int64\n",
      "2nd Flr SF         2930 non-null int64\n",
      "Low Qual Fin SF    2930 non-null int64\n",
      "Gr Liv Area        2930 non-null int64\n",
      "Bsmt Full Bath     2928 non-null float64\n",
      "Bsmt Half Bath     2928 non-null float64\n",
      "Full Bath          2930 non-null int64\n",
      "Half Bath          2930 non-null int64\n",
      "Bedroom AbvGr      2930 non-null int64\n",
      "Kitchen AbvGr      2930 non-null int64\n",
      "Kitchen Qual       2930 non-null object\n",
      "TotRms AbvGrd      2930 non-null int64\n",
      "Functional         2930 non-null object\n",
      "Fireplaces         2930 non-null int64\n",
      "Garage Cars        2929 non-null float64\n",
      "Garage Area        2929 non-null float64\n",
      "Paved Drive        2930 non-null object\n",
      "Wood Deck SF       2930 non-null int64\n",
      "Open Porch SF      2930 non-null int64\n",
      "Enclosed Porch     2930 non-null int64\n",
      "3Ssn Porch         2930 non-null int64\n",
      "Screen Porch       2930 non-null int64\n",
      "Pool Area          2930 non-null int64\n",
      "Misc Val           2930 non-null int64\n",
      "Mo Sold            2930 non-null int64\n",
      "Yr Sold            2930 non-null int64\n",
      "Sale Type          2930 non-null object\n",
      "Sale Condition     2930 non-null object\n",
      "SalePrice          2930 non-null int64\n",
      "dtypes: float64(9), int64(28), object(34)\n",
      "memory usage: 1.6+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#1 drop columns with more than 25% missing values\n",
    "missing_val = data.isnull().sum()\n",
    "drop_cols = missing_val[(missing_val/len(data)) > 0.05]\n",
    "data = data.drop(columns=drop_cols.index)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 2930 entries, 0 to 2929\n",
      "Data columns (total 64 columns):\n",
      "Order              2930 non-null int64\n",
      "PID                2930 non-null int64\n",
      "MS SubClass        2930 non-null int64\n",
      "MS Zoning          2930 non-null object\n",
      "Lot Area           2930 non-null int64\n",
      "Street             2930 non-null object\n",
      "Lot Shape          2930 non-null object\n",
      "Land Contour       2930 non-null object\n",
      "Utilities          2930 non-null object\n",
      "Lot Config         2930 non-null object\n",
      "Land Slope         2930 non-null object\n",
      "Neighborhood       2930 non-null object\n",
      "Condition 1        2930 non-null object\n",
      "Condition 2        2930 non-null object\n",
      "Bldg Type          2930 non-null object\n",
      "House Style        2930 non-null object\n",
      "Overall Qual       2930 non-null int64\n",
      "Overall Cond       2930 non-null int64\n",
      "Year Built         2930 non-null int64\n",
      "Year Remod/Add     2930 non-null int64\n",
      "Roof Style         2930 non-null object\n",
      "Roof Matl          2930 non-null object\n",
      "Exterior 1st       2930 non-null object\n",
      "Exterior 2nd       2930 non-null object\n",
      "Mas Vnr Area       2907 non-null float64\n",
      "Exter Qual         2930 non-null object\n",
      "Exter Cond         2930 non-null object\n",
      "Foundation         2930 non-null object\n",
      "BsmtFin SF 1       2929 non-null float64\n",
      "BsmtFin SF 2       2929 non-null float64\n",
      "Bsmt Unf SF        2929 non-null float64\n",
      "Total Bsmt SF      2929 non-null float64\n",
      "Heating            2930 non-null object\n",
      "Heating QC         2930 non-null object\n",
      "Central Air        2930 non-null object\n",
      "1st Flr SF         2930 non-null int64\n",
      "2nd Flr SF         2930 non-null int64\n",
      "Low Qual Fin SF    2930 non-null int64\n",
      "Gr Liv Area        2930 non-null int64\n",
      "Bsmt Full Bath     2928 non-null float64\n",
      "Bsmt Half Bath     2928 non-null float64\n",
      "Full Bath          2930 non-null int64\n",
      "Half Bath          2930 non-null int64\n",
      "Bedroom AbvGr      2930 non-null int64\n",
      "Kitchen AbvGr      2930 non-null int64\n",
      "Kitchen Qual       2930 non-null object\n",
      "TotRms AbvGrd      2930 non-null int64\n",
      "Functional         2930 non-null object\n",
      "Fireplaces         2930 non-null int64\n",
      "Garage Cars        2929 non-null float64\n",
      "Garage Area        2929 non-null float64\n",
      "Paved Drive        2930 non-null object\n",
      "Wood Deck SF       2930 non-null int64\n",
      "Open Porch SF      2930 non-null int64\n",
      "Enclosed Porch     2930 non-null int64\n",
      "3Ssn Porch         2930 non-null int64\n",
      "Screen Porch       2930 non-null int64\n",
      "Pool Area          2930 non-null int64\n",
      "Misc Val           2930 non-null int64\n",
      "Mo Sold            2930 non-null int64\n",
      "Yr Sold            2930 non-null int64\n",
      "Sale Type          2930 non-null object\n",
      "Sale Condition     2930 non-null object\n",
      "SalePrice          2930 non-null int64\n",
      "dtypes: float64(9), int64(28), object(27)\n",
      "memory usage: 1.4+ MB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#2 drop text cols with more than 1 missing val\n",
    "text_cols = data.select_dtypes(include=[\"object\"]).isnull().sum()\n",
    "text_cols_drop = text_cols[text_cols > 0]\n",
    "data = data.drop(columns=text_cols_drop.index)\n",
    "print(data.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    64\n",
       "dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#3 fill in numerical columns with less than 5% missing values with the mode\n",
    "numerical_cols = data.select_dtypes(include=['int', 'float'])\n",
    "num_missing_val = data.isnull().sum()\n",
    "mode_replace_cols = num_missing_val[((num_missing_val/len(data)) < 0.05) &((num_missing_val/len(data)) > 0)] \n",
    "for col in mode_replace_cols.index:\n",
    "    data[col].fillna(int(data[col].mode()), inplace=True)\n",
    "data.isnull().sum().value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "#4 new features to built: \n",
    "# a) how old has it been at sale YEARS_sold\n",
    "# b) how long has last remod been ago years_remod\n",
    "\n",
    "data[\"years_sold\"] = data[\"Yr Sold\"] - data[\"Year Built\"]\n",
    "data[\"years_remod\"] = data[\"Yr Sold\"] - data[\"Year Remod/Add\"]\n",
    "\n",
    "data = data.drop(data[data[\"years_sold\"] < 0].index)\n",
    "data = data.drop(data[data[\"years_remod\"] < 0].index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      114\n",
       "1      218\n",
       "2       90\n",
       "3       60\n",
       "4       76\n",
       "5       66\n",
       "6       66\n",
       "7       51\n",
       "8       44\n",
       "9       50\n",
       "10      40\n",
       "11      47\n",
       "12      33\n",
       "13      38\n",
       "14      27\n",
       "15      31\n",
       "16      22\n",
       "17      25\n",
       "18      14\n",
       "19      16\n",
       "20       9\n",
       "21       9\n",
       "22      12\n",
       "23      12\n",
       "24       8\n",
       "25      11\n",
       "26      17\n",
       "27       9\n",
       "28      19\n",
       "29      30\n",
       "      ... \n",
       "97      11\n",
       "98      10\n",
       "99      13\n",
       "100      5\n",
       "101      1\n",
       "102      1\n",
       "103      3\n",
       "104      1\n",
       "106     10\n",
       "107      5\n",
       "108      7\n",
       "109      5\n",
       "110      5\n",
       "111      1\n",
       "112      2\n",
       "113      1\n",
       "114      2\n",
       "115      1\n",
       "117      3\n",
       "118      2\n",
       "119      2\n",
       "120      1\n",
       "122      1\n",
       "125      1\n",
       "126      1\n",
       "127      2\n",
       "128      2\n",
       "129      2\n",
       "135      1\n",
       "136      1\n",
       "Name: years_sold, Length: 127, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"years_sold\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0     238\n",
       "1     193\n",
       "2     104\n",
       "3      97\n",
       "4     111\n",
       "5      91\n",
       "6      83\n",
       "7      75\n",
       "8      85\n",
       "9      71\n",
       "10     66\n",
       "11     62\n",
       "12     59\n",
       "13     57\n",
       "14     46\n",
       "15     37\n",
       "16     38\n",
       "17     33\n",
       "18     18\n",
       "19     21\n",
       "20     18\n",
       "21     15\n",
       "22     13\n",
       "23     18\n",
       "24     10\n",
       "25     14\n",
       "26     17\n",
       "27     18\n",
       "28     22\n",
       "29     26\n",
       "     ... \n",
       "31     50\n",
       "32     37\n",
       "33     29\n",
       "34     30\n",
       "35     22\n",
       "36     37\n",
       "37     30\n",
       "38     27\n",
       "39     47\n",
       "40     30\n",
       "41     26\n",
       "42     33\n",
       "43     27\n",
       "44     34\n",
       "45     22\n",
       "46     25\n",
       "47     28\n",
       "48     26\n",
       "49     27\n",
       "50     23\n",
       "51     31\n",
       "52     29\n",
       "53     30\n",
       "54     21\n",
       "55     23\n",
       "56    112\n",
       "57     79\n",
       "58     76\n",
       "59     78\n",
       "60     42\n",
       "Name: years_remod, Length: 61, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"years_remod\"].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "## Drop columns that aren't useful for ML\n",
    "data = data.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "## Drop columns that leak info about the final sale\n",
    "data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55275.367312413066"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(data):\n",
    "    #1 drop columns with more than 25% missing values\n",
    "    missing_val = data.isnull().sum()\n",
    "    drop_cols = missing_val[(missing_val/len(data)) > 0.05]\n",
    "    data = data.drop(columns=drop_cols.index)\n",
    "    \n",
    "    #2 drop text cols with more than 1 missing val\n",
    "    text_cols = data.select_dtypes(include=[\"object\"]).isnull().sum()\n",
    "    text_cols_drop = text_cols[text_cols > 0]\n",
    "    data = data.drop(columns=text_cols_drop.index)\n",
    "\n",
    "    #3 fill in numerical columns with less than 5% missing values with the mode\n",
    "    numerical_cols = data.select_dtypes(include=['int', 'float'])\n",
    "    num_missing_val = data.isnull().sum()\n",
    "    mode_replace_cols = num_missing_val[((num_missing_val/len(data)) < 0.05) &((num_missing_val/len(data)) > 0)] \n",
    "    for col in mode_replace_cols.index:\n",
    "        data[col].fillna(int(data[col].mode()), inplace=True)\n",
    "        \n",
    "    #4 new features to built: \n",
    "    # a) how old has it been at sale YEARS_sold\n",
    "    # b) how long has last remod been ago years_remod\n",
    "\n",
    "    data[\"years_sold\"] = data[\"Yr Sold\"] - data[\"Year Built\"]\n",
    "    data[\"years_remod\"] = data[\"Yr Sold\"] - data[\"Year Remod/Add\"]\n",
    "\n",
    "    data = data.drop(data[data[\"years_sold\"] < 0].index)\n",
    "    data = data.drop(data[data[\"years_remod\"] < 0].index)\n",
    "    \n",
    "    ## Drop columns that aren't useful for ML\n",
    "    data = data.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "    ## Drop columns that leak info about the final sale\n",
    "    data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    return data\n",
    "\n",
    "data = pd.read_csv('../datasets/AmesHousing.tsv', delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "filtered_df = select_features(transform_df)\n",
    "rmse = train_and_test(filtered_df)\n",
    "\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Starting to select features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SalePrice         1.000000\n",
       "Overall Qual      0.799262\n",
       "Gr Liv Area       0.706780\n",
       "Garage Cars       0.647877\n",
       "Garage Area       0.640401\n",
       "Total Bsmt SF     0.632280\n",
       "1st Flr SF        0.621676\n",
       "Year Built        0.558426\n",
       "Full Bath         0.545604\n",
       "Year Remod/Add    0.532974\n",
       "Garage Yr Blt     0.526965\n",
       "Mas Vnr Area      0.508285\n",
       "TotRms AbvGrd     0.495474\n",
       "Fireplaces        0.474558\n",
       "BsmtFin SF 1      0.432914\n",
       "Lot Frontage      0.357318\n",
       "Wood Deck SF      0.327143\n",
       "Open Porch SF     0.312951\n",
       "Half Bath         0.285056\n",
       "Bsmt Full Bath    0.276050\n",
       "Name: SalePrice, dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "numerical_cols = data.select_dtypes(include=['int', 'float']).columns\n",
    "cols = data[numerical_cols].corr()[\"SalePrice\"].sort_values(ascending=False)[0:20]\n",
    "cols"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "testing a model with numerical features and variable pearson correlation value, here: 0.4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "36706.41086991501"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(data):\n",
    "    #1 drop columns with more than 5% missing values\n",
    "    missing_val = data.isnull().sum()\n",
    "    drop_cols = missing_val[(missing_val/len(data)) > 0.05]\n",
    "    data = data.drop(columns=drop_cols.index)\n",
    "    \n",
    "    #2 drop text cols with more than 1 missing val\n",
    "    text_cols = data.select_dtypes(include=[\"object\"]).isnull().sum()\n",
    "    text_cols_drop = text_cols[text_cols > 0]\n",
    "    data = data.drop(columns=text_cols_drop.index)\n",
    "\n",
    "    #3 fill in numerical columns with less than 5% missing values with the mode\n",
    "    numerical_cols = data.select_dtypes(include=['int', 'float'])\n",
    "    num_missing_val = data.isnull().sum()\n",
    "    mode_replace_cols = num_missing_val[((num_missing_val/len(data)) < 0.05) &((num_missing_val/len(data)) > 0)] \n",
    "    for col in mode_replace_cols.index:\n",
    "        data[col].fillna(int(data[col].mode()), inplace=True)\n",
    "        \n",
    "    #4 new features to built: \n",
    "    # a) how old has it been at sale YEARS_sold\n",
    "    # b) how long has last remod been ago years_remod\n",
    "\n",
    "    data[\"years_sold\"] = data[\"Yr Sold\"] - data[\"Year Built\"]\n",
    "    data[\"years_remod\"] = data[\"Yr Sold\"] - data[\"Year Remod/Add\"]\n",
    "\n",
    "    data = data.drop(data[data[\"years_sold\"] < 0].index)\n",
    "    data = data.drop(data[data[\"years_remod\"] < 0].index)\n",
    "    \n",
    "    ## Drop columns that aren't useful for ML\n",
    "    data = data.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "    ## Drop columns that leak info about the final sale\n",
    "    data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    return data\n",
    "\n",
    "def select_features(df, corr_treshold):\n",
    "    numerical_cols = df.select_dtypes(include=['int', 'float']).columns\n",
    "    cols = df[numerical_cols].corr()[\"SalePrice\"].sort_values(ascending=False)[df[numerical_cols].corr()[\"SalePrice\"] > corr_treshold].index\n",
    "    return df[cols]\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df.iloc[:1460]\n",
    "    test = df.iloc[1460:]\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    features = train.select_dtypes(include=['int', 'float']).drop(columns=\"SalePrice\").columns\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "    test_predictions = lr.predict(test[features])\n",
    "\n",
    "    test_mse = mean_squared_error(test_predictions, test['SalePrice'])\n",
    "    \n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return test_rmse\n",
    "\n",
    "data = pd.read_csv('../datasets/AmesHousing.tsv', delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "rmses = {}\n",
    "filtered_df = select_features(transform_df, 0.4)\n",
    "rmse = train_and_test(filtered_df)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "identifying and adding categorical columns to the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['MS SubClass',\n",
       " 'MS Zoning',\n",
       " 'Street',\n",
       " 'Land Contour',\n",
       " 'Lot Config',\n",
       " 'Neighborhood',\n",
       " 'Condition 1',\n",
       " 'Condition 2',\n",
       " 'Bldg Type',\n",
       " 'House Style',\n",
       " 'Roof Style',\n",
       " 'Roof Matl',\n",
       " 'Exterior 1st',\n",
       " 'Exterior 2nd',\n",
       " 'Foundation',\n",
       " 'Heating',\n",
       " 'Central Air']"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## Create a list of column names from documentation that are *meant* to be categorical\n",
    "nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "## Which categorical columns have we still carried with us? We'll test tehse \n",
    "transform_cat_cols = []\n",
    "for col in nominal_features:\n",
    "    if col in transform_df.columns:\n",
    "        transform_cat_cols.append(col)\n",
    "transform_cat_cols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "## How many unique values in each categorical column?\n",
    "uniqueness_counts = transform_df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "## Aribtrary cutoff of 10 unique values (worth experimenting)\n",
    "drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > 10].index\n",
    "transform_df = transform_df.drop(drop_nonuniq_cols, axis=1)\n",
    "\n",
    "## Select just the remaining text columns and convert to categorical\n",
    "text_cols = transform_df.select_dtypes(include=['object'])\n",
    "for col in text_cols:\n",
    "    transform_df[col] = transform_df[col].astype('category')\n",
    "    \n",
    "## Create dummy columns and add back to the dataframe!\n",
    "transform_df = pd.concat([\n",
    "    transform_df, \n",
    "    pd.get_dummies(transform_df.select_dtypes(include=['category']))\n",
    "], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Testing a model with numerical and categorical features (dummies) with 5 or less unique values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33029.341096815835\n",
      "Index(['Overall Qual', 'Year Built', 'Year Remod/Add', 'Mas Vnr Area',\n",
      "       'BsmtFin SF 1', 'Total Bsmt SF', '1st Flr SF', 'Gr Liv Area',\n",
      "       'Full Bath', 'TotRms AbvGrd', 'Fireplaces', 'Garage Cars',\n",
      "       'Garage Area', 'years_sold', 'years_remod', 'Street_Grvl',\n",
      "       'Street_Pave', 'Lot Shape_IR1', 'Lot Shape_IR2', 'Lot Shape_IR3',\n",
      "       'Lot Shape_Reg', 'Land Contour_Bnk', 'Land Contour_HLS',\n",
      "       'Land Contour_Low', 'Land Contour_Lvl', 'Utilities_AllPub',\n",
      "       'Utilities_NoSeWa', 'Utilities_NoSewr', 'Lot Config_Corner',\n",
      "       'Lot Config_CulDSac', 'Lot Config_FR2', 'Lot Config_FR3',\n",
      "       'Lot Config_Inside', 'Land Slope_Gtl', 'Land Slope_Mod',\n",
      "       'Land Slope_Sev', 'Bldg Type_1Fam', 'Bldg Type_2fmCon',\n",
      "       'Bldg Type_Duplex', 'Bldg Type_Twnhs', 'Bldg Type_TwnhsE',\n",
      "       'Exter Qual_Ex', 'Exter Qual_Fa', 'Exter Qual_Gd', 'Exter Qual_TA',\n",
      "       'Exter Cond_Ex', 'Exter Cond_Fa', 'Exter Cond_Gd', 'Exter Cond_Po',\n",
      "       'Exter Cond_TA', 'Heating QC_Ex', 'Heating QC_Fa', 'Heating QC_Gd',\n",
      "       'Heating QC_Po', 'Heating QC_TA', 'Central Air_N', 'Central Air_Y',\n",
      "       'Kitchen Qual_Ex', 'Kitchen Qual_Fa', 'Kitchen Qual_Gd',\n",
      "       'Kitchen Qual_Po', 'Kitchen Qual_TA', 'Functional_Maj1',\n",
      "       'Functional_Maj2', 'Functional_Min1', 'Functional_Min2',\n",
      "       'Functional_Mod', 'Functional_Sal', 'Functional_Sev', 'Functional_Typ',\n",
      "       'Paved Drive_N', 'Paved Drive_P', 'Paved Drive_Y'],\n",
      "      dtype='object')\n"
     ]
    }
   ],
   "source": [
    "def transform_features(data):\n",
    "    #1 drop columns with more than 5% missing values\n",
    "    missing_val = data.isnull().sum()\n",
    "    drop_cols = missing_val[(missing_val/len(data)) > 0.05]\n",
    "    data = data.drop(columns=drop_cols.index)\n",
    "    \n",
    "    #2 drop text cols with more than 1 missing val\n",
    "    text_cols = data.select_dtypes(include=[\"object\"]).isnull().sum()\n",
    "    text_cols_drop = text_cols[text_cols > 0]\n",
    "    data = data.drop(columns=text_cols_drop.index)\n",
    "\n",
    "    #3 fill in numerical columns with less than 5% missing values with the mode\n",
    "    numerical_cols = data.select_dtypes(include=['int', 'float'])\n",
    "    num_missing_val = data.isnull().sum()\n",
    "    mode_replace_cols = num_missing_val[((num_missing_val/len(data)) < 0.05) &((num_missing_val/len(data)) > 0)] \n",
    "    for col in mode_replace_cols.index:\n",
    "        data[col].fillna(int(data[col].mode()), inplace=True)\n",
    "        \n",
    "    #4 new features to built: \n",
    "    # a) how old has it been at sale YEARS_sold\n",
    "    # b) how long has last remod been ago years_remod\n",
    "\n",
    "    data[\"years_sold\"] = data[\"Yr Sold\"] - data[\"Year Built\"]\n",
    "    data[\"years_remod\"] = data[\"Yr Sold\"] - data[\"Year Remod/Add\"]\n",
    "\n",
    "    data = data.drop(data[data[\"years_sold\"] < 0].index)\n",
    "    data = data.drop(data[data[\"years_remod\"] < 0].index)\n",
    "    \n",
    "    ## Drop columns that aren't useful for ML\n",
    "    data = data.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "    ## Drop columns that leak info about the final sale\n",
    "    data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    return data\n",
    "\n",
    "def select_features(df, corr_treshold=0.4, unique_treshold=5):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < corr_treshold].index, axis=1)\n",
    "    ## Create a list of column names from documentation that are *meant* to be categorical\n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    ## Which categorical columns have we still carried with us? We'll test tehse \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "    \n",
    "    ## How many unique values in each categorical column?\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    ## Aribtrary cutoff of 10 unique values (worth experimenting)\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > unique_treshold].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "\n",
    "    ## Select just the remaining text columns and convert to categorical\n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    ## Create dummy columns and add back to the dataframe!\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df):\n",
    "    train = df.iloc[:1460]\n",
    "    test = df.iloc[1460:]\n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    \n",
    "    features = train.select_dtypes(include=['int', 'float', 'uint8']).drop(columns=\"SalePrice\").columns\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(train[features], train['SalePrice'])\n",
    "\n",
    "    test_predictions = lr.predict(test[features])\n",
    "\n",
    "    test_mse = mean_squared_error(test_predictions, test['SalePrice'])\n",
    "    \n",
    "    test_rmse = np.sqrt(test_mse)\n",
    "\n",
    "    return (test_rmse, features)\n",
    "\n",
    "data = pd.read_csv('../datasets/AmesHousing.tsv', delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "rmses = {}\n",
    "filtered_df = select_features(transform_df, 0.4, 5)\n",
    "rmse, features = train_and_test(filtered_df)\n",
    "\n",
    "print(rmse)\n",
    "print(features)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Including cross validation on the above model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "24911190.294953994\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[25169.037789564376,\n",
       " 248847914.77582255,\n",
       " 24790.18142704602,\n",
       " 27293.714550249057,\n",
       " 29257.599087634197,\n",
       " 29039.67539631784,\n",
       " 23877.40225310704,\n",
       " 24327.49278896487,\n",
       " 48639.37223378415,\n",
       " 31593.698190780753]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def transform_features(data):\n",
    "    #1 drop columns with more than 5% missing values\n",
    "    missing_val = data.isnull().sum()\n",
    "    drop_cols = missing_val[(missing_val/len(data)) > 0.05]\n",
    "    data = data.drop(columns=drop_cols.index)\n",
    "    \n",
    "    #2 drop text cols with more than 1 missing val\n",
    "    text_cols = data.select_dtypes(include=[\"object\"]).isnull().sum()\n",
    "    text_cols_drop = text_cols[text_cols > 0]\n",
    "    data = data.drop(columns=text_cols_drop.index)\n",
    "\n",
    "    #3 fill in numerical columns with less than 5% missing values with the mode\n",
    "    numerical_cols = data.select_dtypes(include=['int', 'float'])\n",
    "    num_missing_val = data.isnull().sum()\n",
    "    mode_replace_cols = num_missing_val[((num_missing_val/len(data)) < 0.05) &((num_missing_val/len(data)) > 0)] \n",
    "    for col in mode_replace_cols.index:\n",
    "        data[col].fillna(int(data[col].mode()), inplace=True)\n",
    "        \n",
    "    #4 new features to built: \n",
    "    # a) how old has it been at sale YEARS_sold\n",
    "    # b) how long has last remod been ago years_remod\n",
    "\n",
    "    data[\"years_sold\"] = data[\"Yr Sold\"] - data[\"Year Built\"]\n",
    "    data[\"years_remod\"] = data[\"Yr Sold\"] - data[\"Year Remod/Add\"]\n",
    "\n",
    "    data = data.drop(data[data[\"years_sold\"] < 0].index)\n",
    "    data = data.drop(data[data[\"years_remod\"] < 0].index)\n",
    "    \n",
    "    ## Drop columns that aren't useful for ML\n",
    "    data = data.drop([\"PID\", \"Order\"], axis=1)\n",
    "\n",
    "    ## Drop columns that leak info about the final sale\n",
    "    data = data.drop([\"Mo Sold\", \"Sale Condition\", \"Sale Type\", \"Yr Sold\"], axis=1)\n",
    "    return data\n",
    "\n",
    "def select_features(df, corr_treshold=0.4, unique_treshold=5):\n",
    "    numerical_df = df.select_dtypes(include=['int', 'float'])\n",
    "    abs_corr_coeffs = numerical_df.corr()['SalePrice'].abs().sort_values()\n",
    "    df = df.drop(abs_corr_coeffs[abs_corr_coeffs < corr_treshold].index, axis=1)\n",
    "    ## Create a list of column names from documentation that are *meant* to be categorical\n",
    "    nominal_features = [\"PID\", \"MS SubClass\", \"MS Zoning\", \"Street\", \"Alley\", \"Land Contour\", \"Lot Config\", \"Neighborhood\", \n",
    "                    \"Condition 1\", \"Condition 2\", \"Bldg Type\", \"House Style\", \"Roof Style\", \"Roof Matl\", \"Exterior 1st\", \n",
    "                    \"Exterior 2nd\", \"Mas Vnr Type\", \"Foundation\", \"Heating\", \"Central Air\", \"Garage Type\", \n",
    "                    \"Misc Feature\", \"Sale Type\", \"Sale Condition\"]\n",
    "\n",
    "    ## Which categorical columns have we still carried with us? We'll test tehse \n",
    "    transform_cat_cols = []\n",
    "    for col in nominal_features:\n",
    "        if col in df.columns:\n",
    "            transform_cat_cols.append(col)\n",
    "    \n",
    "    ## How many unique values in each categorical column?\n",
    "    uniqueness_counts = df[transform_cat_cols].apply(lambda col: len(col.value_counts())).sort_values()\n",
    "    ## Aribtrary cutoff of 10 unique values (worth experimenting)\n",
    "    drop_nonuniq_cols = uniqueness_counts[uniqueness_counts > unique_treshold].index\n",
    "    df = df.drop(drop_nonuniq_cols, axis=1)\n",
    "\n",
    "    ## Select just the remaining text columns and convert to categorical\n",
    "    text_cols = df.select_dtypes(include=['object'])\n",
    "    for col in text_cols:\n",
    "        df[col] = df[col].astype('category')\n",
    "    \n",
    "    ## Create dummy columns and add back to the dataframe!\n",
    "    df = pd.concat([df, pd.get_dummies(df.select_dtypes(include=['category']))], axis=1)\n",
    "    \n",
    "    return df\n",
    "\n",
    "def train_and_test(df, kfolds=0):\n",
    "    \n",
    "    \n",
    "    from sklearn.linear_model import LinearRegression\n",
    "    from sklearn.metrics import mean_squared_error\n",
    "    from sklearn.model_selection import KFold\n",
    "    \n",
    "    features = df.select_dtypes(include=['int', 'float', 'uint8']).drop(columns=\"SalePrice\").columns\n",
    "    lr = LinearRegression()\n",
    "    \n",
    "    if kfolds == 0:\n",
    "        train = df.iloc[:1460]\n",
    "        test = df.iloc[1460:]\n",
    "\n",
    "        lr.fit(train[features], train['SalePrice'])\n",
    "        test_predictions = lr.predict(test[features])\n",
    "        rmse = mean_squared_error(test_predictions, test['SalePrice'])**(1/2)\n",
    "        return rmse\n",
    "                                                                        \n",
    "    if kfolds == 1:\n",
    "        shuffled_index = np.random.permutation(df.index)\n",
    "        df = df.reindex(shuffled_index)\n",
    "\n",
    "        fold_one = df.iloc[0:1460].copy()\n",
    "        fold_two = df.iloc[1460:].copy()\n",
    "        \n",
    "        lr.fit(fold_one[features], fold_one['SalePrice'])\n",
    "        test_predictions = lr.predict(fold_two[features])\n",
    "        rmse_1 = mean_squared_error(test_predictions, fold_two['SalePrice'])**(1/2)\n",
    "        \n",
    "        lr.fit(fold_two[features], fold_two['SalePrice'])\n",
    "        test_predictions = lr.predict(fold_one[features])\n",
    "        rmse_2 = mean_squared_error(test_predictions, fold_one['SalePrice'])**(1/2)\n",
    "        rmse = (rmse_1 +rmse_2) /2\n",
    "        return rmse\n",
    "    \n",
    "    else:\n",
    "        rmse_value = []\n",
    "        kf = KFold(n_splits=kfolds, shuffle=True)\n",
    "        rmse_values = []\n",
    "        for train_index, test_index, in kf.split(df):\n",
    "            train = df.iloc[train_index]\n",
    "            test = df.iloc[test_index]\n",
    "            lr.fit(train[features], train[\"SalePrice\"])\n",
    "            predictions = lr.predict(test[features])\n",
    "            mse = mean_squared_error(test[\"SalePrice\"], predictions)\n",
    "            rmse = np.sqrt(mse)\n",
    "            rmse_values.append(rmse)\n",
    "        avg_rmse = np.mean(rmse_values)\n",
    "        return (avg_rmse, rmse_values)\n",
    "\n",
    "data = pd.read_csv('../datasets/AmesHousing.tsv', delimiter=\"\\t\")\n",
    "transform_df = transform_features(data)\n",
    "filtered_df = select_features(transform_df, 0.4, 5)\n",
    "rmse_avg, rmse_values = train_and_test(filtered_df, kfolds=10)\n",
    "\n",
    "print(rmse_avg)\n",
    "\n",
    "rmse_values\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
